#!/usr/bin/env perl
#
# Author: petr.danecek@sanger
#

use strict;
use warnings;
use Carp;
use Utils;

my $runner = myRunner->new();
$runner->run();

exit;

#--------------------------------

package myRunner;
use base qw(Runner);
use strict;
use warnings;

sub new
{
    my ($class,@args) = @_;
    my $self = $class->SUPER::new(@args);

    $$self{do_clean} = 1;
    $$self{limits} = { runtime=>24*60 };
    $$self{debug_chunks} = 0;
    $$self{merge_pops} = 0;
    $$self{whole_genome_bams} = 1;
	$$self{config_version} = '47417d8';
    $$self{_sampleconf} = q[
            # For sanity checking that your config file is not obsolete. Update the version key in your 
            #  config file to get rid of the warnings.
            version  => '] .$$self{config_version}. q[',

            # Add -P ILLUMINA or -P SLX if the BAMs contain also reads from different platforms. 
            mpileup  => '/nfs/users/nfs_p/pd3/sandbox/svn/samtools/singletons/samtools-qsum mpileup -EDVS -C50 -pm3 -F0.2 -d 10000',
            bcftools => '/nfs/users/nfs_p/pd3/sandbox/svn/samtools/singletons/bcftools-qsum view -Ngvm0.99',
            
            bams     => '/lustre/scratch105/projects/g1k/MAIN-ANALYSIS/20101123-whole-genome-calling/merge_across_bams.list',
            fa_ref   => '/lustre/scratch105/projects/g1k/ref/main_project/human_g1k_v37.fasta',
            mysql    => 'mysql -sN -uXXX -pXXX -hmcs4a -P 3306 g1k_meta',   # To get the sex. Optional when assumed_sex or sample_list is defined below.

            limits   => { runtime=>24*60 },
            do_clean => 1,         # Remove runner's temporary files

            merge_chroms => 0,     # Create whole-genome VCF? This can produce *huge* files for thousands of samples

            ploidy   =>
            {
                default => 2,
                X =>
                [
                    # These are pseudoautosomal: 60001-2699520, 154931044-155270560, call with ploidy 2
                    { region=>'1-60000', M=>1 },
                    { region=>'2699521-154931043', M=>1 },
                ],
                Y =>
                [
                    # No chrY in females and one copy in males
                    { region=>'1-59373566', M=>1, F=>0 },
                ],
            },
            
            chroms => [ qw(1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y) ],
            pops   =>
            {
                # With no populations, at least 'pooled' must be given
                pooled => [ '.' ],
            
                # The population groups can be defined either as BAM file name substrings (attempted first)
                #   or, if none of the regex finds a matching BAM, as a list of samples.
                AMR => [ qw(MXL CLM PUR) ],
                AFR => [ qw(YRI LWK ASW) ],
                ASN => [ qw(CHB CHS JPT) ],
                EUR => [ qw(CEU TSI FIN GBR IBS) ],
            },

            # Do not merge population VCFs into one VCF. The merged set can find more rare variants
            #   than the pooled set.
            merge_pops => 0,
            
            # Set the depth filter (+/D=N) to about twice the average depth.
            filter => 'vcf-annotate -f +',
            
            chunk_size        => 1_000_000,
            debug_chunks      => 0,
            shuffle_chunks    => 0,         # Process chunks in random order to randomize disk access
            keep_bcfs         => 1,
            chunks_overlap    => 0,
            whole_genome_bams => 1,         # Set to 0 if BAMs are splitted by chromosome. In such a case, the bams must contain '*chrom$chr.' in the name.
            assumed_sex       => undef,     # Set to 'F' for females, 'M' males and undef mysql key above if the DB shouldn't be used.
            sample_list       => undef,     # Provide list of samples with sex. In this case, neither mysql nor assumed_sex keys are required.

            # Do specific regions only (whitespace delimited file with the columns CHR,FROM,TO)
            #   regions => 'regions.list',

            # Chunk-specific options will be applied to chunks with a non-zero overlap
            #   chunk_options => { 
            #       '10:42000001-43000000' => { mpileup=>'...'  } 
            #   },

            # Uncomment and modify as necessary if VQSR filtering should be applied. The default annotations listed below will be by the pipeline
            # vqsr_filtering => 
            # {
            #     jar => q[java -Xmx4800m -Xms4800m -Xss280m -server -XX:+UseSerialGC -jar /nfs/users/nfs_s/sm15/src/GATK/dist/GenomeAnalysisTK.jar],
            #     recal_snps => q[
            #             -T VariantRecalibrator --mode SNP -l INFO
            #             -resource:hapmap,known=false,training=true,truth=true,prior=15.0 /lustre/scratch105/projects/g1k/ref/broad_resources_b37/hapmap_3.3.b37.sites.vcf.gz
            #             -resource:omni,known=false,training=true,truth=false,prior=12.0 /lustre/scratch105/projects/g1k/ref/broad_resources_b37/1000G_omni2.5.b37.sites.vcf.gz
            #             -resource:dbsnp,known=true,training=false,truth=false,prior=8.0 /lustre/scratch105/projects/g1k/ref/broad_resources_b37/dbsnp_132.b37.vcf.gz
            #             --target_titv 2.3 --ts_filter_level 99.85 
            #             --maxGaussians 4
            #             -an MSD -an MDV -an MSQ -an ICF -an DP -an SB -an VDB
            #     ],
            #     recal_indels => q[
            #             -T VariantRecalibrator --mode INDEL -l INFO
            #             -resource:mills,VCF,known=true,training=true,truth=true,prior=12.0 /lustre/scratch105/projects/g1k/ref/broad_resources_b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz
            #             -resource:g1k,known=false,training=true,truth=false,prior=10.0 /lustre/scratch105/projects/g1k/mapping/resources/ALL.wgs.low_coverage_vqsr.20101123.indels.sites.vcf.gz
            #             --target_titv 2.3 --ts_filter_level 99.85 
            #             --maxGaussians 4
            #             -an MSD -an MDV -an MSQ -an ICF -an DP -an SB -an VDB
            #     ],
            #     filter_snps   => q[ -T ApplyRecalibration --ts_filter_level 99.85 --mode SNP ],
            #     filter_indels => q[ -T ApplyRecalibration --ts_filter_level 99.85 --mode INDEL ],
            #     limits   => { runtime=>24*60, memory=>5_000 },
            # },
    ]."\n";

    $$self{usage} .= 
        "Usage: run-mpileup\n" .
        "Options:\n" .
        "   -c, --clean             Clean all temporary files (and do nothing else)\n" .
        "   -m, --mrProper          Clean all temporary files, including the population directories and BCFs, leaving only toplevel VCFs (and do nothing else)\n" .
        "   -o, --outdir <dir>      Output directory\n" .
        "\n";

    return $self;
}

sub parse_args
{
    my ($self) = @_;
    while (defined(my $arg=shift(@ARGV)))
    {
        if ( $arg eq '-c' or $arg eq '--clean' ) { $$self{clean}=1; next; }
        if ( $arg eq '-m' or $arg eq '--mrProper' ) { $$self{mrProper}=1; next; }
        if ( $arg eq '-o' or $arg eq '--outdir' ) { $$self{outdir}=shift(@ARGV); next; }
        $self->throw();
    }
    if ( !exists($$self{outdir}) ) { $self->throw("Expected -o option."); }

    # This lengthy code checks if mandatory parameters are present and fills the defaults issuing warnings when doing so.
	if ( !exists($$self{version}) or $$self{version} ne $$self{config_version} )
	{
		$self->warn("Warning: Your config file may be out of date, the latest version key is \"$$self{config_version}\". Please run with +sampleconf to see what changed.\n");
	}
    if ( !exists($$self{bams}) ) { $self->throw("The 'bams' config key not present\n"); }
    if ( !exists($$self{mysql}) && !$$self{assumed_sex} && !$$self{sample_list} ) { $self->throw("None of the config keys 'mysql', 'assumed_sex' or 'sample_list' present\n"); }
    if ( !exists($$self{chroms}) ) 
    { 
        $$self{chroms} = [ qw(1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y) ];
        $self->warn("The 'chroms' config key not present, assuming: ".join(' ',@{$$self{chroms}})."\n"); 
    }
    if ( !exists($$self{pops}) ) 
    { 
        # 'pooled' must be always present
        $$self{pops} = { pooled => [ '.' ] };
        $self->warn("The 'pops' config key not present, assuming: pooled => [ '.' ]\n"); 
    }
    if ( !exists($$self{fa_ref}) ) 
    { 
        $$self{fa_ref} = '/lustre/scratch105/projects/g1k/ref/main_project/human_g1k_v37.fasta';
        $self->warn("The 'fa_ref' config key not present, assuming: $$self{fa_ref}\n"); 
    }
    if ( !exists($$self{ploidy}) ) 
    { 
        $$self{ploidy} = 
        {
            default => 2,
            X => 
            [
                # These are pseudoautosomal: 60001-2699520, 154931044-155270560, call with ploidy 2
                { region=>'1-60000', M=>1 },
                { region=>'2699521-154931043', M=>1 },
            ],
            Y =>
            [
                # No chrY in females and one copy in males
                { region=>'1-59373566', M=>1, F=>0 },
            ],
        };
        $self->warn("The 'ploidy' config key not present, check the code for assumed ploidy and pseudoautosomal regions\n"); 
    }
    if ( !exists($$self{mpileup}) ) 
    { 
        $$self{mpileup} = 'samtools mpileup -DS -C50 -m2 -F0.0005 -d 10000';
        $self->warn("The 'mpileup' config key not present, assuming: $$self{mpileup}\n"); 
    }
    if ( !exists($$self{bcftools}) ) 
    { 
        $$self{bcftools} = 'bcftools view -p 0.99 -vcgN';
        $self->warn("The 'bcftools' config key not present, assuming: $$self{bcftools}\n"); 
    }
    if ( !exists($$self{chunk_size}) ) 
    { 
        $$self{chunk_size} = 1_000_000;
        $self->warn("The 'chunk_size' config key not present, assuming: $$self{chunk_size}\n"); 
    }
    if ( !exists($$self{chunks_overlap}) ) 
    { 
        $$self{chunks_overlap} = 0;
        $self->warn("The 'chunks_overlap' config key not present, assuming: $$self{chunks_overlap}\n"); 
    }
    if ( !exists($$self{keep_bcfs}) ) 
    { 
        $$self{keep_bcfs} = 1;
        $self->warn("The 'keep_bcfs' config key not present, assuming: $$self{keep_bcfs}\n"); 
    }
    if ( $$self{clean} ) 
    { 
        $self->clean($$self{outdir});
        $self->all_done;
    }
    if ( $$self{mrProper} )
    {
        $self->mrProper($$self{outdir});
        $self->all_done;
    }
}

sub main
{
    my ($self) = @_;
    $self->parse_args();

    my $outdir = $$self{outdir};
    my @chroms = @{$$self{chroms}};

    if ( $self->is_finished("$outdir/all_done") ) { $self->all_done; }
    if ( !$self->is_finished("$outdir/sanity_checked") ) { $self->check_sanity; }

    # Create sample list for each population group
    while (my ($pop,$value) = each %{$$self{pops}})
    {
        for my $chr (@chroms)
        {
            my $bams_outfile    = "$outdir/lists/chr$chr-$pop.list";
            my $samples_outfile = "$outdir/lists/chr$chr-$pop.samples";
            if ( !$self->is_finished($bams_outfile) )
            {
                $self->population_group_bams_list($bams_outfile,$$self{bams},$chr,$value, $samples_outfile);
            }
            if ( !$self->is_finished($samples_outfile) )
            {
                $self->sample_list($samples_outfile,$bams_outfile);
            }
        }
    }

    # Run mpileup for each population and chunk: first all sites BCFs if requested and then call variants
    my $chunks = $self->get_chunks;

    $self->set_limits(%{$$self{limits}}) unless !exists($$self{limits});
    if ( scalar keys %{$$self{pops}} > 1 ) { $$self{keep_bcfs} = 1; }
    if ( $$self{keep_bcfs} )
    {
        for my $chunk (@$chunks)
        {
            my $chr  = $$chunk{chr};
            my $from = $$chunk{from};
            my $to   = $$chunk{to};
            $self->spawn('all_site_bcfs',"$outdir/pooled/$chr/$chr:$from-$to.bcf",'pooled',$chunk);
        }
        $self->wait;
    }

    # Call the variants
	$self->write_annot_file();
    for my $pop (keys %{$$self{pops}})
    {
        for my $chunk (@$chunks)
        {
            my $chr  = $$chunk{chr};
            my $from = $$chunk{from};
            my $to   = $$chunk{to};
            if ( $self->is_finished("$outdir/$pop/$chr.vcf.gz") ) { next; }
            $self->spawn('call_variants',"$outdir/$pop/$chr/$chr:$from-$to.vcf.gz",$pop,$chunk);
        }
    }
    $self->wait;
    $self->set_limits(runtime=>undef);
    
    $$self{shuffle_chunks} = 0; # chunks need to be in genomic order from here on
    
    # Create the merged set if there are more population groups (pooled + two others)
    if ( $$self{merge_pops} && scalar keys %{$$self{pops}} > 2 )
    {
        for my $chunk (@$chunks)
        {
            my $chr  = $$chunk{chr};
            my $from = $$chunk{from};
            my $to   = $$chunk{to};
            my @vcfs = ();
            for my $pop (keys %{$$self{pops}})
            {
                if ( $pop eq 'pooled' ) { next; }
                push @vcfs, "$outdir/$pop/$chr/$chr:$from-$to.vcf.gz";
            }
            $self->spawn('merge_vcfs',"$outdir/merged/$chr/$chr:$from-$to.vcf.gz","$outdir/pooled/$chr/$chr:$from-$to.bcf",\@vcfs);
        }

        # Work with the merged set only from now (otherwise comment the next line)
        delete($$self{pops});
        $$self{pops}{merged} = 1;
    }
    $self->wait;

	# Merge the files and apply filtering. There are four possible cases: with or without VQSR, 
	#	whole-genome or per-chromosome files
	my @vcfs;
    if ( exists($$self{vqsr_filtering}) ) 
	{  
		# Create whole genome file with sites only, apply filtering and VQSR. 
		if ( exists($$self{vqsr_filtering}{limits}) ) { $self->set_limits(%{$$self{vqsr_filtering}{limits}}); }
		for my $pop (keys %{$$self{pops}})
		{
			$self->spawn('run_vqsr',"$outdir/$pop/vqsr.sites.vcf.gz",$pop,$chunks);
		}
		$self->wait;
		$self->set_limits(memory=>undef);
		for my $pop (keys %{$$self{pops}})
		{
			if ( $$self{merge_chroms} ) 
			{ 
				my $outfile = "$outdir/$pop/all.vqsr.vcf.gz";
				$self->spawn('combine_vqsr',$outfile,"$outdir/$pop/vqsr.sites.vcf.gz",$pop,'.');
				push @vcfs, $outfile;
			}
			else 
			{ 
				for my $chr (@chroms) 
				{ 
					my $outfile = "$outdir/$pop/$chr.vqsr.vcf.gz";
					$self->spawn('combine_vqsr',$outfile,"$outdir/$pop/vqsr.sites.vcf.gz",$pop,$chr);
					push @vcfs, $outfile;
				}
			}
		}
		$self->wait;
	}
	else
	{
		# Apply filtering, no VQSR
		for my $pop (keys %{$$self{pops}})
		{
			if ( $$self{merge_chroms} ) 
			{ 
				my $outfile = "$outdir/$pop/all.vcf.gz";
				$self->spawn('concat_vcfs',$outfile,$pop,'.',$chunks); 
				push @vcfs, $outfile;
			}
			else 
			{ 
				for my $chr (@chroms) 
				{ 
					my $outfile = "$outdir/$pop/$chr.vcf.gz";
					$self->spawn('concat_vcfs',$outfile,$pop,$chr,$chunks);
					push @vcfs, $outfile;
				} 
			}
		}
		$self->wait;
	}

    # Run summary stats
    for my $vcf (@vcfs)
    {
        $self->spawn('vcf_stats',"$vcf.stats",$vcf,q[awk '/^#/||$7=="PASS"']);
		my $filt = $vcf; $filt =~ s/.vcf.gz/.filt.vcf.gz/;
        $self->spawn('apply_filter',$filt,$vcf);
    }
    $self->wait;

    # Run performance stats and clean
    $self->spawn('runtime_stats',"$outdir/runtime");
    $self->wait;
    $self->clean($outdir) unless !$$self{do_clean};

    $self->cmd("touch $outdir/all_done");
    $self->all_done;
}

sub mrProper
{
    my ($self,$outdir) = @_;
    for my $pop (keys %{$$self{pops}})
    {
        $self->cmd("rm -rf $outdir/$pop");
    }
    $self->clean($outdir);
}

sub clean
{
    my ($self,$outdir) = @_;
    $self->SUPER::clean($outdir);
    my $chunks = $self->get_chunks;
    for my $pop (keys %{$$self{pops}})
    {
        for my $chunk (@$chunks)
        {
            my $chr  = $$chunk{chr};
            my $from = $$chunk{from};
            my $to   = $$chunk{to};
            for my $suffix (qw(samples vcf.gz vcf.gz.tbi))
            {
                my $file = "$outdir/$pop/$chr/$chr:$from-$to.$suffix";
                unlink($file) unless !-e $file;
            }
        }
    }
}

sub runtime_stats
{
    my ($self,$outfile) = @_;
    $self->cmd("mkdir -p $outfile.part");
    $self->cmd("runtime-stats $$self{outdir} -p $outfile.part/graph > $outfile.part/stats.txt");
    open(my $fh,'>',"$outfile.part/info.txt") or $self->throw("$outfile.part/info.txt: $!");
    print $fh $$self{_about};
    close($fh);
    rename("$outfile.part",$outfile) or $self->throw("rename $outfile.part $outfile: $!");
}

sub cmd
{
    my ($self,$cmd) = @_;
    $cmd =~ s/\n/ /g;
    return Utils::CMD($cmd,{verbose=>$$self{_verbose}});
}

sub check_sanity
{
    my ($self) = @_;

    # Check that the -P option corresponds to PL in the BAMs
    if ( !($$self{mpileup}=~/-\S*P\s+(\S+)/) ) { return; }
    my %pl = map { $_=>1 } split(/,/,$1);
    my %bam_pls = ();

    open(my $fh,'<',$$self{bams}) or $self->throw("$$self{bams}: $!");
    while (my $bam=<$fh>)
    {
        chomp($bam);
        my @rgs = `samtools view -H $bam | grep ^\@RG`;
        for my $rg (@rgs)
        {
            if ( !($rg=~/\tPL:(\S+)/) ) { next; }
            $bam_pls{$1} = 1;
        }
    }
    close($fh);

    for my $pl (keys %pl)
    {
        if ( !exists($bam_pls{$pl}) ) { $self->throw("The platform \"$pl\" not present in any of the BAMs.\n"); }
    }
    `mkdir -p $$self{outdir}`;
    $self->cmd("touch $$self{outdir}/sanity_checked");
}

sub open_file
{
    my ($self,$file) = @_;
    if ( ($file=~m{^(.+)/[^/]+$}) && ! -d $1 ) { $self->cmd("mkdir -p $1"); }
    open(my $fh,'>',$file) or $self->throw("$file: $!");
    return $fh;
}

sub population_group_bams_list
{
    my ($self,$outfile,$bam_list,$chr,$pops,$samples_fname) = @_;

    open(my $in,'<',$bam_list) or $self->throw("$bam_list: $!");
    my $out = $self->open_file("$outfile.part");
    my $printed = 0;
    while (my $line=<$in>)
    {
        # If the BAMs are split by chr, we are applying to regex's to select by chromosome
        #   and by the population name. Otherwise, only population regex is used.
        if ( !$$self{whole_genome_bams} && !($line=~/chrom$chr\./) ) { next; }
        for my $pop (@$pops)
        {
            if ( !($line=~/$pop/) ) { next; }
            print $out $line;
            $printed = 1;
            last;
        }
    }
    close($in) or $self->throw("close $bam_list");

    if ( !$printed )
    { 
        # No BAM was identified. In that case, the population should be interpreted as
        #   sample name regex's. Read BAM headers and find out the exact sample names and
        #   list of BAMs. The regex may cause problems in future, this may be replaced by
        #   an exact match in find_bams_with_samples.
        #
        my ($bams,$samples) = $self->find_bams_with_samples($bam_list,$pops);
        if ( !@$bams ) 
        { 
            if ( !$$self{whole_genome_bams} ) 
            {
                $self->throw("The BAMs not named as chrom$chr.bam, please unset the whole_genome_bams config key\n");
            }
            $self->throw("No matching BAM found for chr$chr; searched in file names (/chrom$chr\\./) and sample names: ",join(',',@$pops),"\n"); 
        }
        print $out join("\n", @$bams), "\n";
        close($out) or $self->throw("close $outfile.part");

        if ( defined $$self{sample_list} )
        {
            $self->cmd("cp $$self{sample_list} $samples_fname");
            undef $out;
        }
        else 
        {
            $out = $self->open_file($samples_fname);
            my $sexes = $self->get_sample_sex(@$samples);
            for my $sample (sort keys %$sexes)
            {
                print $out "$sample\t$$sexes{$sample}\n";
            }
        }
    }
    if ( defined $out ) { close($out) or $self->throw("close $samples_fname"); }

    rename("$outfile.part",$outfile) or $self->throw("rename $outfile.part $outfile: $!");
}

# Returns list of BAMs and samples which match the regex's from the sample_list
sub find_bams_with_samples
{
    my ($self,$bam_list,$sample_list) = @_;

    my (%bams,%samples);

    open(my $in,'<',$bam_list) or $self->throw("$bam_list: $!");
    while (my $bam=<$in>)
    {
        chomp($bam);

        open(my $rgs,"samtools view -H $bam |") or $self->throw("samtools view -H $bam: $!");
        while (my $rg=<$rgs>)
        {
            if ( !($rg=~/^\@RG/) ) { next; }
            if ( !($rg=~/SM:(\S+)/) ) { next; }
            my $sample = $1;
            for my $re (@$sample_list)
            {
                if ( ($sample=~/$re/) ) 
                { 
                    $bams{$bam} = 1;
                    $samples{$sample} = 1;
                    last;
                }
            }
        }
        close($rgs);
    }
    close($in);

    my @bams = sort keys %bams;
    my @samples = sort keys %samples;
    return (\@bams,\@samples);
}

sub get_sample_sex
{
    my ($self,@samples) = @_;
    my $sexes;
    for my $sample (@samples)
    {
        my $sex;
        if ( !$$self{mysql} ) { $sex = $$self{assumed_sex}; }
        else
        {
            my @sex = $self->cmd(qq[$$self{mysql} -e 'SELECT sex FROM individual WHERE name="$sample"']);
            if ( !@sex ) { $self->throw("No info for $sample?\n"); }
            $sex = $sex[0];
            chomp($sex);
        }
        if ( !($sex=~/^[MF]$/) ) { $self->throw("Neither male nor female? Expected 'F' or 'M', got '$sex'."); }
        $$sexes{$sample} = $sex;
    }
    return $sexes;
}

sub sample_list
{
    my ($self,$outfile,$bams) = @_;

    if ( defined $$self{sample_list} )
    {
        $self->cmd("cp $$self{sample_list} $outfile");
        return;
    }

    my %samples;

    # Now fill the ploidy information
    open(my $in,'<',$bams) or $self->throw("$bams: $!");
    while (my $bam=<$in>)
    {
        chomp($bam);

        open(my $rgs,"samtools view -H $bam |") or $self->throw("samtools view -H $bam: $!");
        while (my $rg=<$rgs>)
        {
            if ( !($rg=~/^\@RG/) ) { next; }
            if ( $rg=~/SM:(\S+)/ ) { $samples{$1}=1; }
        }
        close($rgs);
    }
    close($in);

    open(my $out,'>',"$outfile.part") or $self->throw("$outfile.part: $!");
    my $sexes = $self->get_sample_sex(keys %samples);
    for my $sample (sort keys %samples)
    {
        print $out "$sample\t$$sexes{$sample}\n";
    }
    close($out) or $self->throw("close $outfile.part");

    rename("$outfile.part",$outfile) or $self->throw("rename $outfile.part $outfile: $!");
}

sub get_chunks
{
    my ($self) = @_;

    my $regions = $$self{regions} ? $self->read_regions($$self{regions}) : $self->read_fai("$$self{fa_ref}.fai",$$self{chroms});

    my @chunks;
    for my $region (@$regions)
    {
        my $pos     = $$region{from};
        my $end_pos = $$region{to};
        while ($pos<$end_pos)
        {
            my $from = $pos;
            my $to   = $from+$$self{chunk_size}-1;

            if ( $to>$end_pos ) { $to=$end_pos; }

            push @chunks, { chr=>$$region{chr}, from=>$from, to=>$to };

            $pos += $$self{chunk_size} - $$self{chunks_overlap};
            if ( $pos<1 ) { $self->throw("The split size too small [$$self{chunk_size}]?\n"); }

            if ( $$self{debug_chunks} && scalar @chunks>=$$self{debug_chunks} ) { return \@chunks; }
        }
    }

    if ( $$self{shuffle_chunks} )
    {
        use Math::Random;
        random_set_seed_from_phrase(1,1);
        @chunks = random_permutation(@chunks);
    }

    return \@chunks;
}

sub read_regions
{
    my ($self,$file) = @_;
    open(my $fh,'<',$file) or $self->throw("$file: $!"); 
    my @regions;
    while (my $line=<$fh>)
    {
        chomp($line);
        if ( !($line=~/^(\S+)\s+(\d+)\s+(\d+)\s*$/) ) { $self->throw("Could not parse the regions file $file: [$line]"); }
        push @regions, { chr=>$1, from=>$2, to=>$3 };
    }
    return \@regions;
}

sub read_fai
{
    my ($self,$fai,$regexs) = @_;

    # Determine the chromosomes and their lengths
    open(my $fh,'<',$fai) or $self->throw("$fai: $!"); 
    my @chr_lengths;
    while (my $line=<$fh>)
    {
        my ($chr,$from,$to);
        for my $regex (@$regexs)
        {
            if ( !($line=~/^($regex)\t(\d+)/i) ) { next; }
            $chr  = $1;
            $from = 1;
            $to   = $2;
            last;
        }
        if ( !defined $chr ) { next; }
        if ( !exists($$self{ploidy}{$chr}) ) 
        {
            push @chr_lengths, { chr=>$chr, from=>$from, to=>$to };
            next;
        }

        # Split the chunks as necessary
        for my $reg (@{$$self{ploidy}{$chr}})
        {
            my ($start,$end) = split(/-/,$$reg{region});
            if ( $start>$from )
            {
                push @chr_lengths, { chr=>$chr, from=>$from, to=>$start-1 };
            }
            push @chr_lengths, { chr=>$chr, from=>$start, to=>$end };
            $from = $end+1;
        }
        if ( $from<$to )
        {
            push @chr_lengths, { chr=>$chr, from=>$from, to=>$to };
        }
    }
    close($fh);
    return \@chr_lengths;
}

sub ploidy_defaults
{
    my ($self,$chr,$from,$to) = @_;
    my $mploidy = $$self{ploidy}{default};
    my $fploidy = $$self{ploidy}{default};
    if ( !exists($$self{ploidy}{$chr}) ) { return ($mploidy,$fploidy); }
    for my $reg (@{$$self{ploidy}{$chr}})
    {
        my ($start,$end) = split(/-/,$$reg{region});

        # Require at least one end to be within the interval
        if ( $from>=$start && $from<=$end or $to>=$start && $to<=$end )
        {
            if ( exists($$reg{M}) ) { $mploidy=$$reg{M}; }
            if ( exists($$reg{F}) ) { $fploidy=$$reg{F}; }
            return ($mploidy,$fploidy);
        }
    }
    return ($mploidy,$fploidy);
}

sub set_chunk_options
{
    my ($self,$chr,$from,$to) = @_;
    if ( !exists($$self{chunk_options}) ) { return; }
    my $hit;
    for my $chunk (keys %{$$self{chunk_options}})
    {
        if ( !($chunk=~/^([^:]+):(\d+)-(\d+)$/) ) { $self->throw("Could not parse the chunk_options: [$chunk]"); }
        if ( $chr ne $1 ) { next; }
        if ( $2>$to ) { next; }
        if ( $3<$from ) { next; }
        $hit = $chunk;
        last;
    }
    if ( !defined $hit )
    {
        if ( exists($$self{ori_chunk_options}) ) 
        {
            $self->set_options($$self{ori_chunk_options},$self);
        }
        return;
    }
    if ( !exists($$self{ori_chunk_options}) )
    {
        $$self{ori_chunk_options} = {};
        $self->set_options($self,$$self{ori_chunk_options},keys %{$$self{chunk_options}{$hit}});
    }
    $self->set_options($$self{chunk_options}{$hit},$self);
}

sub set_options
{
    my ($self,$src,$tgt,@keys) = @_;
    if ( !scalar @keys ) { @keys = keys %$src }
    for my $key (@keys)
    {
        $$tgt{$key} = $$src{$key};
    }
}

sub all_site_bcfs
{
    my ($self,$outfile,$pop,$chunk) = @_;

    my $chr  = $$chunk{chr};
    my $from = $$chunk{from};
    my $to   = $$chunk{to};

    $self->set_chunk_options($chr,$from,$to);

    my $outdir = $$self{outdir};
    my $bam_list = "$outdir/lists/chr$chr-$pop.list";

    `mkdir -p $outdir/$pop/$chr/` unless -d "$outdir/$pop/$chr";
    my $cmd = "$$self{mpileup} -g -r $chr:$from-$to -b $bam_list -f $$self{fa_ref} > $outfile.part";
    $self->cmd($cmd);

    rename("$outfile.part",$outfile) or $self->throw("rename $outfile.part $outfile: $!");
}

sub call_variants
{
    my ($self,$outfile,$pop,$chunk) = @_;

    my $outdir = $$self{outdir};
    my $chr  = $$chunk{chr};
    my $from = $$chunk{from};
    my $to   = $$chunk{to};

    $self->set_chunk_options($chr,$from,$to);

    `mkdir -p $outdir/$pop/$chr/` unless -d "$outdir/$pop/$chr";

    # Create sample list with correct ploidy info
    my $sample_list = "$outdir/$pop/$chr/$chr:$from-$to.samples";
    if ( !$self->is_finished($sample_list) )
    {
        my ($mploidy,$fploidy) = $self->ploidy_defaults($chr,$from,$to);
        open(my $in,'<',"$outdir/lists/chr$chr-$pop.samples") or $self->throw("$outdir/lists/chr$chr-$pop.samples: $!");
        open(my $out,'>',$sample_list) or $self->throw("$sample_list: $!");
        while (my $line=<$in>)
        {
            if ( !($line=~/^(\S+)\s+([MF])$/) ) { chomp($line); $self->throw("Could not parse [$outdir/lists/chr$chr-$pop.samples]: [$line]\n"); }
            if ( $2 eq 'M' && !$mploidy ) { next; }
            if ( $2 eq 'F' && !$fploidy ) { next; }
            print $out "$1\t" .($2 eq 'M' ? $mploidy : $fploidy). "\n";
        }
        close($out) or $self->throw("close failed: $sample_list");
        close($in) or $self->throw("close failed: $outdir/lists/chr$chr-$pop.samples");
    }

    my $cmd;
    if ( $$self{keep_bcfs} )
    {
        $cmd = "$$self{bcftools} -s $sample_list $outdir/pooled/$chr/$chr:$from-$to.bcf";
    }
    else
    {
        my $bam_list = "$outdir/lists/chr$chr-$pop.list";
        $cmd = "$$self{mpileup} -ug -r $chr:$from-$to -b $bam_list -f $$self{fa_ref} | $$self{bcftools} -s $sample_list -";
    }
    $self->cmd("$cmd | vcf-annotate --fill-ICF -f $$self{annot_file} | bgzip -c > $outfile.part");
    $self->tabix_part($outfile);
}

sub tabix_part
{
    my ($self,$vcf) = @_;
    $self->cmd("tabix -p vcf -f $vcf.part");
    rename("$vcf.part.tbi","$vcf.tbi");
    rename("$vcf.part",$vcf);
}

sub merge_vcfs
{
    my ($self,$outfile,$bcf,$vcfs) = @_;

    # List of all sites. Use awk, grep has the peculiar property of exiting with error status when no lines are printed
    #   through -v
    $self->cmd(q[vcf-isec -f -n +1 ] .join(' ',@$vcfs). q[ | awk '!($1~/^#/)' | cut -f 1,2 | uniq > ] . "$outfile.sites");

    # Call genotypes for all samples at these positions
    $self->cmd("$$self{bcftools} -l $outfile.sites $bcf | vcf-annotate --fill-ICF -f $$self{annot_file} | bgzip -c > $outfile.part");

    $self->tabix_part($outfile);
}

sub write_annot_file
{
	my ($self) = @_;

    if ( !exists($$self{annot_file}) ) 
    { 
        $$self{annot_file} = "$$self{outdir}/annot.pl";
    }
	if ( -e $$self{annot_file} ) { return; }

	open(my $fh,'>',$$self{annot_file}) or $self->throw("$$self{annot_file}: $!");
	print $fh q[
		{
			header   => [ 
				qq[key=INFO,ID=PV0,Number=1,Type=Float,Description="P-value for strand bias"],
				qq[key=INFO,ID=PV1,Number=1,Type=Float,Description="P-value for baseQ bias"],
				qq[key=INFO,ID=PV2,Number=1,Type=Float,Description="P-value for mapQ bias"],
				qq[key=INFO,ID=PV3,Number=1,Type=Float,Description="P-value for tail distance bias"],
				qq[key=INFO,ID=QD,Number=1,Type=Float,Description="Quality By Depth"],
				qq[key=INFO,ID=MSQ,Number=1,Type=Float,Description="Maximum quality across non-ref genotypes"],
				qq[key=INFO,ID=MSD,Number=1,Type=Float,Description="Maximum depth across non-ref genotypes"],
				qq[key=INFO,ID=MDV,Number=1,Type=Integer,Description="Maximum number of high-quality non-reference bases"],
				qq[key=INFO,ID=SB,Number=1,Type=Float,Description="Strand Bias"]
			],
			tag      => 'INFO/PV4',
			name     => 'SplitPV4',
			desc     => 'Split PV4',
			apply_to => 'all',
			test     => sub {
				my @pv = split(/,/,$MATCH);
				my %tags;
				$tags{PV0} = $pv[0];
				$tags{PV1} = $pv[1];
				$tags{PV2} = $pv[2];
				$tags{PV3} = $pv[3];

				my $dp4 = $VCF->get_info_field($$RECORD[7],'DP4'); 
				my @dp4 = split(/,/,$dp4);
				my $sb = 0;
				if ( $dp4[2]+$dp4[3] )
				{
					my $sb = $dp4[2]<$dp4[3] ? ($dp4[2]+1)/($dp4[3]+1) : ($dp4[3]+1)/($dp4[2]+1);
					if ( $dp4[0]+$dp4[1] )
					{
						$sb *= 1 - 0.5 * ($dp4[0]<$dp4[1] ? (1+$dp4[0])/(1+$dp4[1]) : (1+$dp4[1])/(1+$dp4[0]));
					}
					$tags{SB} = sprintf "%.4f", $sb;
				}

				my $igt = $VCF->get_tag_index($$RECORD[8],'GT',':');
				my $igq = $VCF->get_tag_index($$RECORD[8],'GQ',':');
				my $idp = $VCF->get_tag_index($$RECORD[8],'DP',':');
				my $ipl = $VCF->get_tag_index($$RECORD[8],'PL',':');
				my $idv = $VCF->get_tag_index($$RECORD[8],'DV',':');
				my $qd = 0;
				my $nqd = 0;
				my $MSQ = 0;
				my $MSD = 0;
				my $MDV = 0;
				for (my $i=9; $i<@$RECORD; $i++)
				{	
					my @tags = split(/:/,$$RECORD[$i]);
					my @als = $VCF->split_gt($tags[$igt]);
					for my $al (@als)
					{
						if ( $al eq '.' or $al eq '0' ) { next; }
						my $gq = $tags[$igq];
						if ( $MSQ<$gq ) { $MSQ= $gq; }
						my $dp = $tags[$idp];
						if ( $MSD<$dp ) { $MSD = $dp; }
						my $dv = $tags[$idv];
						if ( $MDV<$dv ) { $MDV = $dv; }
						last;
					}

					my $pl = $tags[$ipl];
					my $dp = $tags[$idp];
					my ($rr,$ra,$aa) = split(/,/,$pl);
					if ( $dp && $aa )
					{
						$qd += ($rr+$ra)/$aa/$dp;
						$nqd++;

						if ( !defined $mqd or $qd>$mqd ) { $mqd=$qd; }
					}
					elsif ( $dp && $rr )
					{
						$qd += ($aa+$ra)/$rr/$dp;
						$nqd++;
					}
				}
				$tags{MSQ} = $MSQ;
				$tags{MSD} = $MSD;
				$tags{MDV} = $MDV;
				if ( $nqd ) { $tags{QD} = sprintf "%.4f",$qd/$nqd; }
				if ( scalar keys %tags ) { $$RECORD[7] = $VCF->add_info_field($$RECORD[7],%tags); }
				return $PASS;
			},
		}
	];
	close($fh);
}

sub chunk_sort
{
	if ($$a{chr} eq $$b{chr}) { return $$a{from}<=>$$b{from} }
	return $$a{chr} cmp $$b{chr};
}

sub concat_vcfs
{
	my ($self,$outfile,$pop,$chr,$chunks) = @_;

	my $outdir = $$self{outdir};
	my $chunks_list = "$outdir/$pop/$chr/concat.list";

	open(my $fh,'>',$chunks_list) or $self->throw("$chunks_list: $!");
	for my $chunk (sort chunk_sort @$chunks)
	{
		if ( $chr ne '.' && $$chunk{chr} ne $chr ) { next; }
		my $from = $$chunk{from};
		my $to   = $$chunk{to};
		print $fh "$outdir/$pop/$$chunk{chr}/$$chunk{chr}:$from-$to.vcf.gz\n";
	}
	close($fh) or $self->throw("close $chunks_list");

	my $filter = exists($$self{filter}) ? "| $$self{filter}" : '';
	$self->cmd("vcf-concat -p -f $chunks_list $filter | bgzip -c > $outfile.part");
	$self->tabix_part($outfile);
}

sub run_vqsr
{
    my ($self,$outfile,$pop,$chunks) = @_;

    my $outdir = $$self{outdir};
    my $chunks_list = "$outdir/$pop/concat.list";

    open(my $fh,'>',$chunks_list) or $self->throw("$chunks_list: $!");
	for my $chunk (@$chunks)
    {
		my $chr  = $$chunk{chr};
		my $from = $$chunk{from};
		my $to   = $$chunk{to};
        print $fh "$outdir/$pop/$chr/$chr:$from-$to.vcf.gz\n";
    }
    close($fh) or $self->throw("close $chunks_list");

    my $tmp = $outfile; $tmp =~ s/\.vcf\.gz$//;
    my $concat = "$tmp.raw.vcf.gz";
    if ( ! -e $concat )
    {
        $self->cmd("vcf-concat -p -f $chunks_list | cut -f 1-8 | bgzip -c > $concat.part");
        $self->tabix_part($concat);
    }
    my $conf = $$self{vqsr_filtering};
    my $input = $concat;
    my $output;
    my $tranches;
    for (my $i=95; $i<=100; $i+=0.1) { $tranches .= sprintf(" -tranche %.1f",$i); }
    if ( exists($$conf{recal_snps}) )
    {
        $output = "$tmp.snps.vcf.gz";
        $self->cmd("$$conf{jar} $$conf{recal_snps} -R $$self{fa_ref} --input $input -recalFile $tmp.snps.csv -tranchesFile $tmp.snps.tranches $tranches");
        $self->cmd("$$conf{jar} $$conf{filter_snps} -R $$self{fa_ref} --input $input -recalFile $tmp.snps.csv -tranchesFile $tmp.snps.tranches -o $output");
        $self->cmd("tabix $output");
        $input = $output;
    }
    if ( exists($$conf{recal_indels}) )
    {
        $output = "$tmp.indels.vcf.gz";
        $self->cmd("$$conf{jar} $$conf{recal_indels} -R $$self{fa_ref} --input $input -recalFile $tmp.indels.csv -tranchesFile $tmp.indels.tranches $tranches");
        $self->cmd("$$conf{jar} $$conf{filter_indels} -R $$self{fa_ref} --input $input -recalFile $tmp.indels.csv -tranchesFile $tmp.indels.tranches -o $output");
        $self->cmd("tabix $output");
        $input = $output;
    }
    if ( !defined $output ) { $self->throw("Neither recal_snps nor recal_indels key defined in vqsr_filtering?"); }

	if ( !exists($$self{filter}) )
	{
		Utils::relative_symlink($input,$outfile);
		Utils::relative_symlink("$input.tbi","$outfile.tbi");
	}
	else
	{
		$self->cmd("zcat $input | $$self{filter} | bgzip -c > $outfile.part");
		$self->tabix_part($outfile);
	}
}

sub pad_columns
{
	my ($self,$cols1,$cols2) = @_;
	if ( @$cols1<@$cols2 ) { $self->throw(sprintf "Not ready for this, sorry, expected fewer columns (%d!<%d)", @$cols1,@$cols2); }
	my $has1 = {};
	my $has2 = {};
	for (my $i=0; $i<@$cols1; $i++) { $$has1{$$cols1[$i]} = $i; }
	my $need_map = 0;
	for (my $i=0; $i<@$cols2; $i++) 
	{
		if ( !exists($$has1{$$cols2[$i]}) ) { $self->throw("The column [$$cols2[$i]] not seen previously."); }
		if ( $i != $$has1{$$cols2[$i]} ) { $need_map=1; }
		$$has2{$$cols2[$i]} = $i; 
	}
	if ( @$cols1==@$cols2 && !$need_map ) { return undef; }
	my @map;
	for (my $i=0; $i<@$cols1; $i++)
	{
		my $cname = $$cols1[$i];
		push @map, exists($$has2{$cname}) ? $$has2{$cname} : -1;
	}
	return \@map;
}


# Combine VCFs so that the first 8 columns are taken from the sites file and the genotypes from the list.
# The task is made more difficult by GATK changing indels.
sub combine_vqsr
{
	my ($self,$outfile,$sites,$pop,$chr) = @_;
    my $file_list = "$$self{outdir}/$pop/concat.list";
	open(my $sites_fh,"tabix -h $sites $chr |") or $self->throw("tabix -h $sites $chr: $!");
	open(my $out_fh,"| bgzip -c > $outfile.part") or $self->throw("bgzip -c > $outfile.part: $!");
	open(my $files_fh,'<',$file_list) or $self->throw("$file_list: $!");
	my ($gt_fh,$gt_file,$gt_line,$header_printed,@columns,@header,$column_map);
	while (my $site_line=<$sites_fh>)
	{
		if ( substr($site_line,0,1) eq '#' ) 
		{ 
			if ( $header_printed ) { next; }
			if ( substr($site_line,1,1) eq '#' ) { push @header,$site_line; }	# this header contains GATK's filters
			next; 
		}
		while ( !defined $gt_line )
		{
			if ( defined $gt_fh ) 
			{ 
				close($gt_fh) or $self->throw("close tabix -h $gt_file $chr"); 
				$gt_fh = undef;
			}
			$gt_file = <$files_fh>;
			if ( !defined $gt_file ) { last; }
			chomp($gt_file);
			if ( $header_printed && $chr ne '.' && ($gt_file=~m{/?([^:/]+):[^/]+.vcf.gz$}) ) 
			{ 
				# different chromosome, skip
				if ( $chr ne $1 ) { next; } 
			}
			open($gt_fh,"tabix -h $gt_file $chr |") or $self->throw("tabix -h $gt_file $chr: $!");
			while ($gt_line=<$gt_fh>)
			{
				if ( substr($gt_line,0,1) ne '#' ) { last; }	# data line
				if ( substr($gt_line,1,1) eq '#' ) { next; }	# header line
				
				# column line
				my @cols = split(/\t/,$gt_line);
				if ( !$header_printed )
				{
					@columns = @cols;
					print $out_fh @header;
					print $out_fh $gt_line;
					$header_printed = 1;
					next;
				}
				$column_map = $self->pad_columns(\@columns,\@cols);
			}
		}
		if ( !defined $gt_line ) { $self->throw("Out of sync: no gt_line in $gt_file after $site_line"); }
		my $site_idx=0;
		my $gt_idx=0;
		for (my $i=0; $i<5; $i++) { $site_idx = index($site_line,"\t",$site_idx+1); }
		if ( substr($site_line,0,$site_idx) ne substr($gt_line,0,$site_idx) )
		{
			# Either out of sync or an indel modified by GATK
			my @site_items = split(/\t/,$site_line);
			my @site_alts  = split(/,/,$site_items[4]);
			for (my $i=0; $i<5; $i++) { $gt_idx = index($gt_line,"\t",$gt_idx+1); }
			my @gt_items = split(/\t/, substr($gt_line,0,$gt_idx));
			my @gt_alts  = split(/,/,$gt_items[4]);
			if ( @site_alts != @gt_alts ) { $self->throw("Out of sync: $site_idx\n$site_line$gt_line"); }
			my $site_ref_len = length($site_items[3]);
			my $gt_ref_len = length($gt_items[3]);
			if ( $site_ref_len >= $gt_ref_len ) { $self->throw("Out of sync: $site_idx\n$site_line$gt_line"); }
			my $diff = substr($gt_items[3],$site_ref_len);
			for (my $i=0; $i<@site_alts; $i++)
			{
				if ( $gt_alts[$i] ne $site_alts[$i].$diff ) { $self->throw("Out of sync: $site_idx, [$site_alts[$i]] [$gt_alts[$i].$diff]\n$site_line$gt_line"); }
			}
		}
		else { $gt_idx = $site_idx; }
		print $out_fh substr($site_line,0,-1);
		for (my $i=0; $i<3; $i++) { $gt_idx = index($gt_line,"\t",$gt_idx+1); }
		if ( !defined $column_map )
		{
			print $out_fh substr($gt_line,$gt_idx);
		}
		else
		{
			my @cols = split(/\t/,substr($gt_line,$gt_idx+1));
			chomp($cols[-1]);
			for (my $i=8; $i<@$column_map; $i++)
			{
				my $idx = $$column_map[$i];
				if ( $idx==-1 ) { print $out_fh "\t."; }
				else { print $out_fh "\t",$cols[$idx-8]; }
			}
			print $out_fh "\n";
		}
		$gt_line = <$gt_fh>;
	}
	close($gt_fh) or $self->throw("close tabix -h $gt_file $chr");
	close($files_fh) or $self->throw("close $file_list");
	close($out_fh) or $self->throw("close bgzip -c > $outfile.part");
	close($sites_fh) or $self->throw("close tabix -h $sites $chr");
	$self->tabix_part($outfile);
}

sub vcf_stats
{
    my ($self,$outfile,$vcf,$filter) = @_;
    my $cmd = "zcat $vcf | " .(defined $filter ? "$filter |" : ''). "vcf-stats -s - -p $outfile.part/stats";
    $self->cmd($cmd);
    rename("$outfile.part",$outfile) or $self->throw("rename $outfile.part $outfile: $!");
}

sub apply_filter
{
    my ($self,$outfile,$vcf) = @_;
    $self->cmd(qq[zcat $vcf | awk '/^#/||\$7=="PASS"' | bgzip -c > $outfile.part]);
    $self->tabix_part($outfile);
}


